In this section, we outline ideas for future research in OED. Some ideas are next steps in the greedy EIG maximisation paradigm that has been adopted so far. The ultimate goal of this project would be a probabilistic programming framework that can efficiently design (near) optimal experiments for a wide variety of models and design spaces.

We also look beyond the current framework. Non-greedy strategies, and experiment design with costs both make OED more challenging. We also discuss designing experiments with causal inference in mind, or when models are misspecified. Could we design experiments to expose flaws in our models?

With such a diversity of interesting questions in this area, the difficulty is prioritisation. So far, we have sought to strike the balance between building things that work efficiently on some problems, and maintaining generality. Potential applications, interest and advice will guide future priorities.


\section{Greedy EIG maximisation}
\subsection{Expanding the scope of variational OED}
Variational optimal experiment design as outlined in Chapter~\ref{chap:voed}, whilst a generally applicable idea, is currently limited in practice to (a subset of) GLMMs. The guides are highly structured and exploit knowledge of the models. If we are interested in OED for sequential human-in-the-loop experiments, there is a definite upper limit on acceptable computation time. This would encourage us to delve forwards with simpler models. The objective would be to drive computation time down as far as possible.

On the other hand, our literature review highlighted the interest in a number of other more complex models. When experiments are very expensive or timely, there is scope to allow a much longer OED computation time.

Among `complex' models, nonlinear regression models are foremost. We can broadly divide these into parametric models (e.g. the differential equation model of \cite{vanlier2012}) and Bayesian nonparametric models where the Gaussian process is the leading example. 

For highly nonlinear parametric models, it is likely that we dispense with assuming any knowledge of the nonlinearities and fall back on flexible approximators like deep neural networks.

For Gaussian processes on the other hand, it is likely we can exploit more structure. When considering Gaussian processes models, we should also make the further distinction between the case where $\theta$, the variable of interest, represents the entire GP, and the case where $\theta$ represents the location of the optimum (as in Bayesian optimisation). The latter case has received a great deal of attention~\cite{pes}, and is a problem the community clearly cares about.

We could instead ask: in which cases does OED deliver the greatest benefit? That is, under which conditions would an experimental program without OED, or with inaccurate OED, be inefficient? A partial answer to this question can be given by the interpretation of EIG as epistemic uncertainty in the response (see Section~\ref{sec:onestep} for derivation)
\begin{equation}
	\eig(d) = \entropy{p(y|d)} - \expect_{p(\theta)}[\entropy{p(y|\theta,d)}].
\end{equation}
Thus $\eig(d)$ will be low whenever $p(y|d)$ is certain. This is intuitive -- if our current model already accurately predicts $y$ at query $d$, little we be gained from confirming that outcome. However, high uncertainty in $y|d$ is not enough. We also need the expected aleatoric uncertainty to be low. Put another way, if knowing the exact values of $\theta$ still fails to resolve the uncertainty in the outcome then querying at $d$ will not tell us much about $\theta$. We can manufacture interesting OED problems using these two insights. First, data censoring means that $\entropy{p(y|d)}$ will be low unless we avoid the censored region. Secondly, allowing the strength of random effects to be higher for some $d$ than others means $\entropy{p(y|\theta,d)}$ will be high unless we avoid the noisy region.

One possible problem to explore is modelling distances, for instance using multi-dimensional scaling \cite{torgerson1952multidimensional}. The design would be a pair $d = (x_1, x_2)$ of object to compare. This could become a very interesting problem if i) the response was censored for very dissimilar objects, ii) responses on previous objects allow us to accurately predict the outcome on some others. Both of these ideas could reduce $\entropy{p(y|d)}$ for certain designs. One specific application is in psychology when studying the similarity between concepts \cite{shepard1962analysis}.

\subsection{Importance weighting correction to variational OED}
The variational methods of Section~\ref{sec:voed} are biased and, if $\mathcal{Q}$ is chosen poorly, do not converge to the true EIG. NMC, though sometimes very slow, is a consistent procedure. We explore the connection between the two here. We have
\begin{equation}
	\eig(d) = \iint p(y, \theta | d) \log p(y|\theta, d) \, dy \, d\theta - \int p(y|d) \log \left( \int p(y|\theta,d) p(\theta) \, d\theta \right) \, dy
\end{equation}
and conventional NMC proceeds by estimating the integral $\int p(y|\theta,d) p(\theta) \, d\theta$ using fresh samples from $p(\theta)$. We could instead use $\qp(\theta|y,d)$ as a proposal
\begin{equation}
	\int p(y|\theta,d) p(\theta) \, d\theta = \int p(y|\theta,d) \frac{p(\theta)}{\qp(\theta|y,d)} \qp(\theta|y,d) \, d\theta.
\end{equation}
Using one Monte Carlo sample for this integral reduces to the estimators used in Section~\ref{sec:voed}. If we instead used $M$ samples, we would have a new NMC estimator
\begin{equation}
	\eig(d) \approx \frac{1}{N}\sum_{n=1}^N \left[ \log p(y_n | \theta_n, d) - \log \left(\frac{1}{M} \sum_{m=1}^M p(y_n | \theta_{nm}, d)\frac{p(\theta_{nm})}{\qp(\theta_{nm}|y_n,d)} \right) \right]
\end{equation}
where
\begin{align}
	y_n, \theta_n \simiid & \ p(y, \theta | d) \\
	\theta_{nm}|y_n \simiid & \ \qp(\theta|y_n,d).
\end{align}
and we would have a consistent estimator that likely converges much faster than conventional NMC. Note the connection with the IWAE \cite{iwae}, an importance weighting correction to the VAE ELBO.

It would also be interesting to see if we can find a correction that uses $\qm$, our approximation to the marginal, rather than $\qp$.


\subsection{Estimating the gradient of EIG}
Thus far, we have primarily focused on point estimation of $\eig(d)$. Many optimisation procedures (over $d$) rely instead on estimates of $\nabla_d\,\eig(d)$. We first note that, as $\eig$ is an expectation over $p(y,\theta|d)$, the reparametrization trick and its extensions \cite{tucker2017rebar, rezende2014stochastic} would be attractive here.

Suppose that we use our variational OED estimates in place of true EIG evaluations. Then the global optimisation problem tackled is
\begin{equation}
	\max_d \max_\phi \left\{ \iint p(y, \theta | d) \log \qp (\theta | y, d; \phi)\, dy\, d\theta  \right\} + \entropy{p(\theta)}.
\end{equation}
Rather than a lengthy process of optimising $\phi$ at each step, we could iterate between gradient steps in $\phi$ and $d$ space (or compute a combined gradient step) to reach the global optimum, as is done with the Generative Adversarial Network (GAN) \cite{goodfellow2014generative}. If successful, this approach could make finding local optima of $\eig$ computationally similar in difficulty to evaluating $\eig$ at a single point.
Alternatively, using gradient information within Gaussian process driven Bayesian optimisation \cite{osborne2009gaussian} is possible, and may be preferable in OED where a global optimum is desired.

\subsection{A sequential design framework in a probabilistic language}
Implementation in Pyro has so far focused on EIG estimation procedures. Further software development will bring us closer to a functioning sequential design toolkit. An open question is, having designed and done an experiment, can we  re-use computation from OED to compute the posterior more quickly? When using posterior variational OED, that based on $\qp$, we will already have an approximation to the posterior. An alternative approach using Population Monte Carlo (PMC) was outlined in \cite{vincent2017}.


\subsection{Optional stopping}
As was mentioned very briefly in Section~\ref{sec:optstop}, optional stopping might form part of sequential OED. Statistical analysis of optional stopping has a long history~\cite{chernoff1972sequential}. Which optional stopping rules are we allowed to use in EIG driven sequential experimentation with Bayesian data analysis?  Which conclusions are we able to draw from our posterior when that posterior was created by optionally stopping?


\subsection{EIG and power}
Frequentist statisticians typically design experiments using a notion of statistical power (that is tied to a specific hypothesis). What is the connection between EIG and power?

Our interest in information arises from a belief that optimising overall information will allow us to tackle many downstream tasks. We would like to make a statement like the following: `EIG optimisation is optimal when an unknown problem is to be solved using the final posterior'. Such a problem could be a hypothesis test. It could also be another kind of decision.


\section{Beyond greedy EIG maximisation}
\subsection{Cost and non-greedy optimisation}
Frequently, experimentation is not free and the cost varies with the design. This is particularly the case when the magnitude of the experiment is a design parameter. With the inclusion of costs, we might wish to optimise
\begin{equation}
	U(d) = \eig(d) - \lambda C(d)
\end{equation}
where $C(d)$ is the cost of the design and $\lambda$ is a constant that determines the trade-off between information and cost.

When designing a single experiment, the inclusion of cost seems relatively simple. In the multi-step case, the inclusion of cost may be more important. For example, in a sequential design problem with costs and a finite horizon $T$, it would make sense to perform cheaper experiments at early times. Once some aspects of the system are understood, we can proceed to more expensive experiments with less risk of performing the wrong experiment. In the case of a fixed budget, we would be happy to use up our entire budget at time $T$, but would be much more cautious at time $1$.

Proceeding to the question of non-greedy optimisation more generally, it has been noted that we can view the problem as a POMDP and so generic methods like Partially Observable Monte Carlo Planning \cite{pomcp} are applicable. Suppose we wish to maximise total information gain, possibly including costs. Are there features of the problem that allow us to do significantly better than using generic POMDP solvers?

\subsection{Causal inference}
It is common in science that experiments are performed to learn causal structure or to estimate expectations defined using \textit{do}-calculus \cite{pearl2009causal} such as $\expect[Y | do(X=x)]$. Many flaws in scientific experiment design are the result, not of gaining too little information, but of making inappropriate causal assumptions or incorrectly estimating these sorts of expectations.

How does experiment design for causal inference intersect with experiment design for information? It is possible that causal statistics simply defines a subset $\mathcal{D}' \subseteq \mathcal{D}$ of designs that are valid from a causal inference perspective. We could then seek $\max_{d\in\mathcal{D}'}\ \eig(d)$. Alternatively, information about certain latent variables might be more valuable in determining the causal structure than others, altering the optimisation problem entirely.


\subsection{Model misspecification}
Box told us that all statistical models are wrong \cite{box1976}. How do we design experiments accounting for model misspecification? We could add independent noise to the outcome. This wouldn't change which design is optimal though. We could also encode our model uncertainty in a Bayesian hierarchical model where we sample some $V \in \{0, 1\}$ to decide if we trust our model. If untrusted, we fall back on some high variance model. This would only change design decisions if the fall back model depended on $d$ or $\theta$, or if $V$ was regarded as part of $\theta$.

If we have empirical samples of $y|d$, from previous experiments, we might stand a better chance of at least detecting model misspecification. It's possible that we could even make this the objective of the experimental program.

\subsection{Experiment design for model criticism}
Rather than assuming the model to be true and looking to gain information within the model, suppose instead that we have data from some prior experiments and seek a new experiment to best expose flaws in the whole model. Scientists often criticise models by comparing the posterior predictive and empirical distributions (possibly conditional on some input). Could we turn this into an objective function, similar to EIG, that would let us design experiments to quickly expose flaws in models?


\subsection{Dynamic models}
A foundational assumption in our sequential OED set-up was that experimentation does not change the underlying system. Many systems do change as we experiment with them. In such a system, would the latent variables of interest also change with time? If so, standard Bayesian data analysis would not be appropriate. If some time-invariant characteristics could be found then we might have a better chance. We could still formulate this model as a POMDP in the usual way if $h_{t+1}$ depends only on $h_t$ and $\theta$. A first model to consider might be one with a Markovian structure, i.e. we would allow $y_{t+1}$ to depend on $\theta$ and $d_{t+1}$ as usual, but also on $y_t$ and $d_t$. In such a setting it might be important to explore the entire state space or avoid absorbing states that would terminate learning.


\subsection{Other criteria}
Alternatives to EIG for one-step design abound \cite{chaloner1995}. Particularly interesting are those employed in active learning that target expected misclassification or expected error on a test set. It could be interesting to explore these i) theoretically, to see if EIG is somehow connected to these other criteria, ii) empirically, to see if altering the criterion used actually changes the experiment design significantly.

